import os
from google.cloud import vision
import re

class OCRProcessor:
    def __init__(self, credentials_path=None):
        """
        OCRãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®åˆæœŸåŒ–
        credentials_pathã¯ç„¡è¦–ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼‰
        """
        self.client = vision.ImageAnnotatorClient()
    
    def process_image(self, image_path):
        """
        ç”»åƒã‹ã‚‰ååˆºæƒ…å ±ã‚’æŠ½å‡º
        """
        try:
            print(f"ğŸ” Processing image: {image_path}")
            
            text = self.ocr_image(image_path)
            
            if not text or not text.strip():
                print("âš ï¸ No text detected")
                return None
            
            print(f"ğŸ“ Detected text length: {len(text)} characters")
            
            info = {
                'name': self.extract_name(text),
                'company': self.extract_company(text),
                'email': self.extract_email(text),
                'phone': self.extract_phone(text),
                'mobile': self.extract_mobile(text),
                'address': self.extract_address(text),
                'website': self.extract_website(text),
                'full_text': text
            }
            
            print(f"âœ… Extracted: {info['name']}, {info['company']}")
            
            return info
        
        except Exception as e:
            print(f"âŒ Error in process_image: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def ocr_image(self, image_path):
        """Google Cloud Vision APIã§OCRå®Ÿè¡Œ"""
        try:
            with open(image_path, 'rb') as image_file:
                content = image_file.read()
            
            image = vision.Image(content=content)
            image_context = vision.ImageContext(language_hints=['ja', 'en'])
            
            response = self.client.text_detection(
                image=image,
                image_context=image_context
            )
            
            if response.error.message:
                raise Exception(f'API Error: {response.error.message}')
            
            texts = response.text_annotations
            
            if texts:
                return texts[0].description
            
            return ""
        
        except Exception as e:
            print(f"âŒ OCR Error: {e}")
            raise
    
    def extract_email(self, text):
        """ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’æŠ½å‡º"""
        pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
        emails = re.findall(pattern, text)
        return emails[0] if emails else None
    
    def extract_phone(self, text):
        """å›ºå®šé›»è©±ç•ªå·ã‚’æŠ½å‡º"""
        text_cleaned = text.replace(' ', '').replace('ã€€', '')
        patterns = [
            r'(?:TEL|Tel|tel|é›»è©±)?[:\s]*0\d{1,4}-\d{1,4}-\d{4}',
            r'(?:TEL|Tel|tel|é›»è©±)?[:\s]*0\d{9,10}',
        ]
        
        for pattern in patterns:
            phones = re.findall(pattern, text_cleaned, re.IGNORECASE)
            if phones:
                phone = re.sub(r'(?:TEL|Tel|tel|é›»è©±)[:\s]*', '', phones[0], flags=re.IGNORECASE)
                if not phone.startswith(('070', '080', '090')):
                    return phone
        
        return None
    
    def extract_mobile(self, text):
        """æºå¸¯é›»è©±ç•ªå·ã‚’æŠ½å‡º"""
        text_cleaned = text.replace(' ', '').replace('ã€€', '')
        pattern = r'(?:Mobile|mobile|æºå¸¯|FAX)?[:\s]*0[789]0-?\d{4}-?\d{4}'
        mobiles = re.findall(pattern, text_cleaned, re.IGNORECASE)
        
        for mobile in mobiles:
            if 'FAX' not in mobile and 'fax' not in mobile:
                cleaned = re.sub(r'(?:Mobile|mobile|æºå¸¯)[:\s]*', '', mobile, flags=re.IGNORECASE)
                return cleaned
        
        return None
    
    def extract_name(self, text):
        """åå‰ã‚’æŠ½å‡º"""
        lines = text.split('\n')
        
        for line in lines[:5]:
            line = line.strip()
            if re.match(r'^[\u4E00-\u9FFF]{2,4}[\sã€€]+[\u4E00-\u9FFF]{1,4}$', line):
                return line
            if re.match(r'^[A-Z][a-z]+\s+[A-Z][a-z]+$', line):
                return line
        
        return None
    
    def extract_company(self, text):
        """ä¼šç¤¾åã‚’æŠ½å‡º"""
        keywords = [
            'æ ªå¼ä¼šç¤¾', 'æœ‰é™ä¼šç¤¾', 'åˆåŒä¼šç¤¾', 'åˆè³‡ä¼šç¤¾',
            'ç¤¾å›£æ³•äºº', 'è²¡å›£æ³•äºº', 'åŒ»ç™‚æ³•äºº',
            'Co.', 'Ltd.', 'Inc.', 'Corporation', 'Corp.',
            'K.K.', 'GK'
        ]
        
        lines = text.split('\n')
        
        for line in lines[:10]:
            for keyword in keywords:
                if keyword in line:
                    return line.strip()
        
        return None
    
    def extract_address(self, text):
        """ä½æ‰€ã‚’æŠ½å‡º"""
        zipcode_pattern = r'ã€’?\d{3}-?\d{4}'
        prefectures = [
            'åŒ—æµ·é“', 'é’æ£®çœŒ', 'å²©æ‰‹çœŒ', 'å®®åŸçœŒ', 'ç§‹ç”°çœŒ', 'å±±å½¢çœŒ', 'ç¦å³¶çœŒ',
            'èŒ¨åŸçœŒ', 'æ ƒæœ¨çœŒ', 'ç¾¤é¦¬çœŒ', 'åŸ¼ç‰çœŒ', 'åƒè‘‰çœŒ', 'æ±äº¬éƒ½', 'ç¥å¥ˆå·çœŒ',
            'æ–°æ½ŸçœŒ', 'å¯Œå±±çœŒ', 'çŸ³å·çœŒ', 'ç¦äº•çœŒ', 'å±±æ¢¨çœŒ', 'é•·é‡çœŒ', 'å²é˜œçœŒ',
            'é™å²¡çœŒ', 'æ„›çŸ¥çœŒ', 'ä¸‰é‡çœŒ', 'æ»‹è³€çœŒ', 'äº¬éƒ½åºœ', 'å¤§é˜ªåºœ', 'å…µåº«çœŒ',
            'å¥ˆè‰¯çœŒ', 'å’Œæ­Œå±±çœŒ', 'é³¥å–çœŒ', 'å³¶æ ¹çœŒ', 'å²¡å±±çœŒ', 'åºƒå³¶çœŒ', 'å±±å£çœŒ',
            'å¾³å³¶çœŒ', 'é¦™å·çœŒ', 'æ„›åª›çœŒ', 'é«˜çŸ¥çœŒ', 'ç¦å²¡çœŒ', 'ä½è³€çœŒ', 'é•·å´çœŒ',
            'ç†Šæœ¬çœŒ', 'å¤§åˆ†çœŒ', 'å®®å´çœŒ', 'é¹¿å…å³¶çœŒ', 'æ²–ç¸„çœŒ'
        ]
        
        lines = text.split('\n')
        
        for i, line in enumerate(lines):
            if re.search(zipcode_pattern, line) or any(pref in line for pref in prefectures):
                address = line
                if i + 1 < len(lines):
                    address += ' ' + lines[i + 1]
                return address.strip()
        
        return None
    
    def extract_website(self, text):
        """Webã‚µã‚¤ãƒˆã‚’æŠ½å‡º"""
        patterns = [
            r'https?://[^\s]+',
            r'www\.[^\s]+',
            r'[a-zA-Z0-9.-]+\.(com|co\.jp|jp|net|org|info)'
        ]
        
        for pattern in patterns:
            websites = re.findall(pattern, text, re.IGNORECASE)
            if websites:
                return websites[0].strip()
        
        return None
