import os
from google.cloud import vision
import re
from typing import List, Dict, Optional
import numpy as np
from sklearn.cluster import DBSCAN
from scipy.spatial.distance import cdist

class OCRProcessor:
    def __init__(self, credentials_path=None):
        self.client = vision.ImageAnnotatorClient()
    
    def process_image(self, image_path):
        """ç”»åƒã‹ã‚‰ååˆºæƒ…å ±ã‚’æŠ½å‡ºï¼ˆè¤‡æ•°æšå¯¾å¿œ - é«˜åº¦ç‰ˆï¼‰"""
        try:
            print(f"ğŸ” Processing: {image_path}")
            
            # ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæƒ…å ±ã‚’å–å¾—
            text_blocks = self.ocr_image_with_layout(image_path)
            
            if not text_blocks:
                print("âš ï¸ No text detected")
                return []
            
            print(f"ğŸ“ Found {len(text_blocks)} text blocks")
            
            # DBSCANã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§ååˆºã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            namecard_groups = self.group_text_by_clustering(text_blocks)
            
            print(f"ğŸ“‡ Detected {len(namecard_groups)} namecard(s)")
            
            # å„ååˆºã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
            results = []
            for i, group in enumerate(namecard_groups, 1):
                text = '\n'.join([block['text'] for block in group])
                info = self.extract_info_from_text(text)
                if info and (info.get('name') or info.get('company') or info.get('email')):
                    print(f"âœ… Card {i}: {info.get('name', 'Unknown')}, {info.get('company', 'Unknown')}")
                    results.append(info)
            
            return results if results else None
            
        except Exception as e:
            print(f"âŒ Error in process_image: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def ocr_image_with_layout(self, image_path):
        """Google Cloud Vision APIã§OCRå®Ÿè¡Œï¼ˆãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæƒ…å ±ä»˜ãï¼‰"""
        try:
            with open(image_path, 'rb') as image_file:
                content = image_file.read()
            
            image = vision.Image(content=content)
            image_context = vision.ImageContext(language_hints=['ja', 'en'])
            
            response = self.client.document_text_detection(
                image=image,
                image_context=image_context
            )
            
            if response.error.message:
                raise Exception(f'API Error: {response.error.message}')
            
            text_blocks = []
            
            # ãƒšãƒ¼ã‚¸æƒ…å ±ã‹ã‚‰å„ãƒ–ãƒ­ãƒƒã‚¯ã‚’å–å¾—
            for page in response.full_text_annotation.pages:
                for block in page.blocks:
                    # ãƒ–ãƒ­ãƒƒã‚¯ã®åº§æ¨™
                    vertices = [(v.x, v.y) for v in block.bounding_box.vertices]
                    x_coords = [v[0] for v in vertices]
                    y_coords = [v[1] for v in vertices]
                    
                    # ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
                    block_text = ''
                    for paragraph in block.paragraphs:
                        for word in paragraph.words:
                            word_text = ''.join([symbol.text for symbol in word.symbols])
                            block_text += word_text + ' '
                        block_text += '\n'
                    
                    if block_text.strip():
                        text_blocks.append({
                            'text': block_text.strip(),
                            'x': sum(x_coords) / len(x_coords),
                            'y': sum(y_coords) / len(y_coords),
                            'min_x': min(x_coords),
                            'max_x': max(x_coords),
                            'min_y': min(y_coords),
                            'max_y': max(y_coords),
                            'width': max(x_coords) - min(x_coords),
                            'height': max(y_coords) - min(y_coords),
                            'vertices': vertices
                        })
            
            return text_blocks
        
        except Exception as e:
            print(f"âŒ OCR Error: {e}")
            raise
    
    def group_text_by_clustering(self, text_blocks, max_cards=9):
        """DBSCANã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§ååˆºã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–"""
        if not text_blocks or len(text_blocks) == 0:
            return []
        
        # å˜ä¸€ãƒ–ãƒ­ãƒƒã‚¯ã®å ´åˆ
        if len(text_blocks) == 1:
            return [text_blocks]
        
        # åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        coords = np.array([[block['x'], block['y']] for block in text_blocks])
        
        # ç”»åƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚’æ¨å®šï¼ˆååˆºã‚µã‚¤ã‚ºã®æ¨å®šï¼‰
        x_range = max([b['max_x'] for b in text_blocks]) - min([b['min_x'] for b in text_blocks])
        y_range = max([b['max_y'] for b in text_blocks]) - min([b['min_y'] for b in text_blocks])
        
        # æ¨™æº–çš„ãªååˆºã‚µã‚¤ã‚º: 91mm x 55mm (ç´„ 3.6 : 2.2)
        # epsã‚’ç”»åƒã‚µã‚¤ã‚ºã«åŸºã¥ã„ã¦å‹•çš„ã«è¨­å®š
        eps = min(x_range, y_range) * 0.15  # ç”»åƒã‚µã‚¤ã‚ºã®15%
        
        print(f"ğŸ”§ DBSCAN parameters: eps={eps:.1f}")
        
        # DBSCANã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        clustering = DBSCAN(eps=eps, min_samples=1, metric='euclidean').fit(coords)
        labels = clustering.labels_
        
        # ãƒã‚¤ã‚ºï¼ˆ-1ãƒ©ãƒ™ãƒ«ï¼‰ã¯å€‹åˆ¥ã®ååˆºã¨ã—ã¦æ‰±ã†
        unique_labels = set(labels)
        
        print(f"ğŸ“Š Found {len(unique_labels)} clusters")
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        namecard_groups = []
        
        for label in unique_labels:
            cluster_indices = np.where(labels == label)[0]
            cluster_blocks = [text_blocks[i] for i in cluster_indices]
            
            # ãƒ–ãƒ­ãƒƒã‚¯æ•°ãŒæ¥µç«¯ã«å°‘ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒã‚¤ã‚ºã®å¯èƒ½æ€§ï¼‰
            if len(cluster_blocks) < 1:
                continue
            
            # ã‚¯ãƒ©ã‚¹ã‚¿ã®é ˜åŸŸã‚’è¨ˆç®—
            cluster_min_x = min([b['min_x'] for b in cluster_blocks])
            cluster_max_x = max([b['max_x'] for b in cluster_blocks])
            cluster_min_y = min([b['min_y'] for b in cluster_blocks])
            cluster_max_y = max([b['max_y'] for b in cluster_blocks])
            
            cluster_width = cluster_max_x - cluster_min_x
            cluster_height = cluster_max_y - cluster_min_y
            
            # ååˆºã®ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ãƒã‚§ãƒƒã‚¯ï¼ˆæ¨ªé•·ã®çŸ©å½¢ã§ã‚ã‚‹ã“ã¨ï¼‰
            # æ¨™æº–ååˆº: 91mm x 55mm = 1.65å€
            aspect_ratio = cluster_width / cluster_height if cluster_height > 0 else 0
            
            # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ãŒ0.5ã€œ4ã®ç¯„å›²ãªã‚‰ååˆºã¨ã—ã¦èªè­˜
            if 0.5 <= aspect_ratio <= 4.0:
                # Yåº§æ¨™ã§ã‚½ãƒ¼ãƒˆï¼ˆä¸Šã‹ã‚‰ä¸‹ã¸ï¼‰
                cluster_blocks.sort(key=lambda b: b['y'])
                namecard_groups.append(cluster_blocks)
                print(f"  âœ“ Cluster {label}: {len(cluster_blocks)} blocks, aspect={aspect_ratio:.2f}")
            else:
                print(f"  âœ— Cluster {label}: Invalid aspect ratio {aspect_ratio:.2f}")
        
        # ååˆºã‚’ä½ç½®é †ã«ã‚½ãƒ¼ãƒˆï¼ˆå·¦ã‹ã‚‰å³ã€ä¸Šã‹ã‚‰ä¸‹ï¼‰
        namecard_groups.sort(key=lambda group: (
            min([b['y'] for b in group]),  # Yåº§æ¨™ï¼ˆè¡Œï¼‰
            min([b['x'] for b in group])   # Xåº§æ¨™ï¼ˆåˆ—ï¼‰
        ))
        
        # æœ€å¤§9æšã¾ã§
        return namecard_groups[:max_cards]
    
    def extract_info_from_text(self, text):
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ååˆºæƒ…å ±ã‚’æŠ½å‡º"""
        if not text or not text.strip():
            return None
        
        return {
            'name': self.extract_name(text),
            'company': self.extract_company(text),
            'email': self.extract_email(text),
            'phone': self.extract_phone(text),
            'mobile': self.extract_mobile(text),
            'address': self.extract_address(text),
            'website': self.extract_website(text),
            'full_text': text
        }
    
    def extract_email(self, text):
        emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', text)
        return emails[0] if emails else None
    
    def extract_phone(self, text):
        text = text.replace(' ', '').replace('ã€€', '')
        patterns = [
            r'(?:TEL|Tel|tel|é›»è©±)?[:\s]*0\d{1,4}-\d{1,4}-\d{4}',
            r'(?:TEL|Tel|tel|é›»è©±)?[:\s]*0\d{9,10}'
        ]
        for pattern in patterns:
            phones = re.findall(pattern, text, re.IGNORECASE)
            if phones:
                phone = re.sub(r'(?:TEL|Tel|tel|é›»è©±)[:\s]*', '', phones[0], flags=re.IGNORECASE)
                if not phone.startswith(('070', '080', '090')):
                    return phone
        return None
    
    def extract_mobile(self, text):
        text = text.replace(' ', '').replace('ã€€', '')
        mobiles = re.findall(r'(?:Mobile|mobile|æºå¸¯|FAX)?[:\s]*0[789]0-?\d{4}-?\d{4}', text, re.IGNORECASE)
        for mobile in mobiles:
            if 'FAX' not in mobile and 'fax' not in mobile:
                return re.sub(r'(?:Mobile|mobile|æºå¸¯)[:\s]*', '', mobile, flags=re.IGNORECASE)
        return None
    
    def extract_name(self, text):
        lines = text.split('\n')
        for line in lines[:5]:
            line = line.strip()
            # æ—¥æœ¬èªã®åå‰ï¼ˆå§“åã®é–“ã«ã‚¹ãƒšãƒ¼ã‚¹ï¼‰
            if re.match(r'^[\u4E00-\u9FFF]{2,4}[\sã€€]+[\u4E00-\u9FFF]{1,4}$', line):
                return line
            # è‹±èªã®åå‰
            if re.match(r'^[A-Z][a-z]+\s+[A-Z][a-z]+$', line):
                return line
        return None
    
    def extract_company(self, text):
        keywords = [
            'æ ªå¼ä¼šç¤¾', 'æœ‰é™ä¼šç¤¾', 'åˆåŒä¼šç¤¾', 'åˆè³‡ä¼šç¤¾',
            'ç¤¾å›£æ³•äºº', 'è²¡å›£æ³•äºº', 'åŒ»ç™‚æ³•äºº',
            'Co.', 'Ltd.', 'Inc.', 'Corporation', 'Corp.',
            'K.K.', 'GK', 'LLC'
        ]
        lines = text.split('\n')
        for line in lines[:10]:
            for keyword in keywords:
                if keyword in line:
                    return line.strip()
        return None
    
    def extract_address(self, text):
        prefectures = [
            'åŒ—æµ·é“', 'é’æ£®çœŒ', 'å²©æ‰‹çœŒ', 'å®®åŸçœŒ', 'ç§‹ç”°çœŒ', 'å±±å½¢çœŒ', 'ç¦å³¶çœŒ',
            'èŒ¨åŸçœŒ', 'æ ƒæœ¨çœŒ', 'ç¾¤é¦¬çœŒ', 'åŸ¼ç‰çœŒ', 'åƒè‘‰çœŒ', 'æ±äº¬éƒ½', 'ç¥å¥ˆå·çœŒ',
            'æ–°æ½ŸçœŒ', 'å¯Œå±±çœŒ', 'çŸ³å·çœŒ', 'ç¦äº•çœŒ', 'å±±æ¢¨çœŒ', 'é•·é‡çœŒ', 'å²é˜œçœŒ',
            'é™å²¡çœŒ', 'æ„›çŸ¥çœŒ', 'ä¸‰é‡çœŒ', 'æ»‹è³€çœŒ', 'äº¬éƒ½åºœ', 'å¤§é˜ªåºœ', 'å…µåº«çœŒ',
            'å¥ˆè‰¯çœŒ', 'å’Œæ­Œå±±çœŒ', 'é³¥å–çœŒ', 'å³¶æ ¹çœŒ', 'å²¡å±±çœŒ', 'åºƒå³¶çœŒ', 'å±±å£çœŒ',
            'å¾³å³¶çœŒ', 'é¦™å·çœŒ', 'æ„›åª›çœŒ', 'é«˜çŸ¥çœŒ', 'ç¦å²¡çœŒ', 'ä½è³€çœŒ', 'é•·å´çœŒ',
            'ç†Šæœ¬çœŒ', 'å¤§åˆ†çœŒ', 'å®®å´çœŒ', 'é¹¿å…å³¶çœŒ', 'æ²–ç¸„çœŒ'
        ]
        lines = text.split('\n')
        for i, line in enumerate(lines):
            if re.search(r'ã€’?\d{3}-?\d{4}', line) or any(p in line for p in prefectures):
                address = line
                if i + 1 < len(lines):
                    address += ' ' + lines[i + 1]
                return address.strip()
        return None
    
    def extract_website(self, text):
        patterns = [
            r'https?://[^\s]+',
            r'www\.[^\s]+',
            r'[a-zA-Z0-9.-]+\.(com|co\.jp|jp|net|org|info)'
        ]
        for pattern in patterns:
            websites = re.findall(pattern, text, re.IGNORECASE)
            if websites:
                return websites[0].strip()
        return None
